"""Tests for worker execution backends (local, ssh, container)."""

from __future__ import annotations

import asyncio
import json
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch

import pytest

from mission_control.backends.base import WorkerHandle
from mission_control.backends.container import ContainerBackend
from mission_control.backends.local import LocalBackend
from mission_control.backends.ssh import SSHBackend
from mission_control.config import SSHHostConfig

# ---------------------------------------------------------------------------
# WorkerHandle dataclass
# ---------------------------------------------------------------------------

class TestWorkerHandle:
	def test_defaults(self) -> None:
		"""WorkerHandle sets correct defaults for optional fields."""
		handle = WorkerHandle(worker_id="w1")
		assert handle.worker_id == "w1"
		assert handle.pid is None
		assert handle.workspace_path == ""
		assert handle.backend_metadata == ""

	def test_full_construction(self) -> None:
		"""WorkerHandle stores all provided values."""
		handle = WorkerHandle(
			worker_id="w2",
			pid=12345,
			workspace_path="/tmp/ws",
			backend_metadata='{"host": "server1"}',
		)
		assert handle.worker_id == "w2"
		assert handle.pid == 12345
		assert handle.workspace_path == "/tmp/ws"
		assert handle.backend_metadata == '{"host": "server1"}'


# ---------------------------------------------------------------------------
# ContainerBackend -- all methods raise NotImplementedError
# ---------------------------------------------------------------------------

class TestContainerBackend:
	@pytest.fixture()
	def backend(self) -> ContainerBackend:
		return ContainerBackend()

	async def test_provision_workspace_raises(self, backend: ContainerBackend) -> None:
		with pytest.raises(NotImplementedError):
			await backend.provision_workspace("w1", "/repo", "main")

	async def test_spawn_raises(self, backend: ContainerBackend) -> None:
		with pytest.raises(NotImplementedError):
			await backend.spawn("w1", "/ws", ["echo", "hi"], 60)

	async def test_check_status_raises(self, backend: ContainerBackend) -> None:
		handle = WorkerHandle(worker_id="w1")
		with pytest.raises(NotImplementedError):
			await backend.check_status(handle)

	async def test_get_output_raises(self, backend: ContainerBackend) -> None:
		handle = WorkerHandle(worker_id="w1")
		with pytest.raises(NotImplementedError):
			await backend.get_output(handle)

	async def test_kill_raises(self, backend: ContainerBackend) -> None:
		handle = WorkerHandle(worker_id="w1")
		with pytest.raises(NotImplementedError):
			await backend.kill(handle)

	async def test_release_workspace_raises(self, backend: ContainerBackend) -> None:
		with pytest.raises(NotImplementedError):
			await backend.release_workspace("/ws")

	async def test_cleanup_raises(self, backend: ContainerBackend) -> None:
		with pytest.raises(NotImplementedError):
			await backend.cleanup()


# ---------------------------------------------------------------------------
# LocalBackend
# ---------------------------------------------------------------------------

class TestLocalBackend:
	@pytest.fixture()
	def backend(self) -> LocalBackend:
		"""LocalBackend with a mocked WorkspacePool."""
		with patch("mission_control.backends.local.WorkspacePool") as mock_pool_cls:
			mock_pool_instance = MagicMock()
			mock_pool_cls.return_value = mock_pool_instance
			# Ensure async methods are AsyncMock
			mock_pool_instance.acquire = AsyncMock()
			mock_pool_instance.release = AsyncMock()
			mock_pool_instance.cleanup = AsyncMock()
			mock_pool_instance.initialize = AsyncMock()
			b = LocalBackend(
				source_repo="/repo",
				pool_dir="/pool",
				max_clones=5,
				base_branch="main",
			)
		return b

	def test_init_creates_pool(self) -> None:
		"""Constructor instantiates a WorkspacePool with correct args."""
		with patch("mission_control.backends.local.WorkspacePool") as mock_pool_cls:
			b = LocalBackend(
				source_repo="/repo",
				pool_dir="/pool",
				max_clones=8,
				base_branch="develop",
			)
			mock_pool_cls.assert_called_once_with(
				source_repo="/repo",
				pool_dir="/pool",
				max_clones=8,
				base_branch="develop",
			)
		assert b._processes == {}
		assert b._stdout_bufs == {}

	@patch("mission_control.backends.local.asyncio.create_subprocess_exec")
	async def test_provision_workspace(
		self, mock_exec: AsyncMock, backend: LocalBackend,
	) -> None:
		"""provision_workspace acquires from pool and runs git checkout."""
		backend._pool.acquire.return_value = Path("/pool/clone-1")

		# Mock the git checkout subprocess
		mock_proc = AsyncMock()
		mock_proc.returncode = 0
		mock_proc.communicate = AsyncMock(return_value=(b"", None))
		mock_exec.return_value = mock_proc

		result = await backend.provision_workspace("w1", "/repo", "main")

		assert result == "/pool/clone-1"
		backend._pool.acquire.assert_awaited_once()
		mock_exec.assert_awaited_once()
		# The command should be git checkout -B mc/unit-w1 (force-create for retry support)
		args = mock_exec.call_args
		assert args[0] == ("git", "checkout", "-B", "mc/unit-w1")
		assert args[1]["cwd"] == "/pool/clone-1"

	@patch("mission_control.backends.local.asyncio.create_subprocess_exec")
	async def test_provision_workspace_uses_force_create_branch(
		self, mock_exec: AsyncMock, backend: LocalBackend,
	) -> None:
		"""provision_workspace uses checkout -B (force) so retried units succeed."""
		backend._pool.acquire.return_value = Path("/pool/clone-1")

		mock_proc = AsyncMock()
		mock_proc.communicate = AsyncMock(return_value=(b"", None))
		mock_proc.returncode = 0
		mock_exec.return_value = mock_proc

		await backend.provision_workspace("w1", "/repo", "main")

		args = mock_exec.call_args[0]
		# Should use -B (force create) not -b
		assert args == ("git", "checkout", "-B", "mc/unit-w1")

	@patch("mission_control.backends.local.asyncio.create_subprocess_exec")
	async def test_provision_workspace_checkout_failure_raises(
		self, mock_exec: AsyncMock, backend: LocalBackend,
	) -> None:
		"""provision_workspace raises and releases workspace if checkout fails."""
		backend._pool.acquire.return_value = Path("/pool/clone-1")

		mock_proc = AsyncMock()
		mock_proc.communicate = AsyncMock(return_value=(b"fatal: error", None))
		mock_proc.returncode = 1
		mock_exec.return_value = mock_proc

		with pytest.raises(RuntimeError, match="Failed to create branch"):
			await backend.provision_workspace("w1", "/repo", "main")

		# Should have released the workspace back to the pool
		backend._pool.release.assert_awaited_once_with(Path("/pool/clone-1"))

	async def test_provision_workspace_no_workspace_available(
		self, backend: LocalBackend,
	) -> None:
		"""provision_workspace raises RuntimeError when pool returns None."""
		backend._pool.acquire.return_value = None

		with pytest.raises(RuntimeError, match="No workspace available"):
			await backend.provision_workspace("w1", "/repo", "main")

	@patch("mission_control.backends.local.asyncio.create_subprocess_exec")
	async def test_spawn(self, mock_exec: AsyncMock, backend: LocalBackend) -> None:
		"""spawn creates a subprocess and returns a WorkerHandle."""
		mock_proc = AsyncMock()
		mock_proc.pid = 9999
		mock_exec.return_value = mock_proc

		handle = await backend.spawn("w1", "/ws", ["claude", "code", "--task", "fix"], 120)

		assert handle.worker_id == "w1"
		assert handle.pid == 9999
		assert handle.workspace_path == "/ws"
		mock_exec.assert_awaited_once_with(
			"claude", "code", "--task", "fix",
			cwd="/ws",
			stdout=asyncio.subprocess.PIPE,
			stderr=asyncio.subprocess.STDOUT,
		)
		assert "w1" in backend._processes
		assert backend._stdout_bufs["w1"] == b""

	@patch("mission_control.backends.local.asyncio.create_subprocess_exec")
	async def test_spawn_clears_stdout_collected(self, mock_exec: AsyncMock, backend: LocalBackend) -> None:
		"""spawn should clear _stdout_collected so a reused worker collects output."""
		mock_proc = AsyncMock()
		mock_proc.pid = 1111
		mock_exec.return_value = mock_proc

		# Simulate a prior spawn that already collected output
		backend._stdout_collected.add("w1")

		await backend.spawn("w1", "/ws", ["echo", "hi"], 60)

		# _stdout_collected should no longer contain w1
		assert "w1" not in backend._stdout_collected

	async def test_check_status_running(self, backend: LocalBackend) -> None:
		"""check_status returns 'running' when returncode is None."""
		mock_proc = MagicMock()
		mock_proc.returncode = None
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		assert await backend.check_status(handle) == "running"

	async def test_check_status_completed(self, backend: LocalBackend) -> None:
		"""check_status returns 'completed' when returncode is 0."""
		mock_proc = MagicMock()
		mock_proc.returncode = 0
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		assert await backend.check_status(handle) == "completed"

	async def test_check_status_failed_nonzero(self, backend: LocalBackend) -> None:
		"""check_status returns 'failed' when returncode is non-zero."""
		mock_proc = MagicMock()
		mock_proc.returncode = 1
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		assert await backend.check_status(handle) == "failed"

	async def test_check_status_unknown_worker(self, backend: LocalBackend) -> None:
		"""check_status returns 'failed' for unknown worker_id."""
		handle = WorkerHandle(worker_id="unknown")
		assert await backend.check_status(handle) == "failed"

	async def test_get_output_finished_process(self, backend: LocalBackend) -> None:
		"""get_output returns decoded stdout for a finished process."""
		mock_proc = MagicMock()
		mock_proc.returncode = 0
		mock_stdout = AsyncMock()
		mock_stdout.read = AsyncMock(return_value=b"hello world\n")
		mock_proc.stdout = mock_stdout
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		output = await backend.get_output(handle)
		assert output == "hello world\n"

	async def test_get_output_finished_appends_remaining(self, backend: LocalBackend) -> None:
		"""get_output appends remaining stdout to partial buffer for finished process."""
		mock_proc = MagicMock()
		mock_proc.returncode = 0
		mock_stdout = AsyncMock()
		mock_stdout.read = AsyncMock(return_value=b" world\n")
		mock_proc.stdout = mock_stdout
		backend._processes["w1"] = mock_proc
		# Simulate partial data already read during polling
		backend._stdout_bufs["w1"] = b"hello"

		handle = WorkerHandle(worker_id="w1")
		output = await backend.get_output(handle)
		assert output == "hello world\n"
		# Second call should not re-read (already collected)
		mock_stdout.read.reset_mock()
		output2 = await backend.get_output(handle)
		assert output2 == "hello world\n"
		mock_stdout.read.assert_not_awaited()

	async def test_get_output_unknown_worker(self, backend: LocalBackend) -> None:
		"""get_output returns empty string for unknown worker_id."""
		handle = WorkerHandle(worker_id="unknown")
		assert await backend.get_output(handle) == ""

	async def test_kill(self, backend: LocalBackend) -> None:
		"""kill terminates a running process."""
		mock_proc = MagicMock()
		mock_proc.returncode = None
		mock_proc.kill = MagicMock()
		mock_proc.wait = AsyncMock()
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		await backend.kill(handle)

		mock_proc.kill.assert_called_once()
		mock_proc.wait.assert_awaited_once()

	async def test_kill_already_finished(self, backend: LocalBackend) -> None:
		"""kill is a no-op for an already-finished process."""
		mock_proc = MagicMock()
		mock_proc.returncode = 0
		mock_proc.kill = MagicMock()
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		await backend.kill(handle)

		mock_proc.kill.assert_not_called()

	async def test_release_workspace(self, backend: LocalBackend) -> None:
		"""release_workspace delegates to pool.release with a Path."""
		await backend.release_workspace("/pool/clone-1")
		backend._pool.release.assert_awaited_once_with(Path("/pool/clone-1"))

	async def test_cleanup(self, backend: LocalBackend) -> None:
		"""cleanup kills all running processes and clears state."""
		running = MagicMock()
		running.returncode = None
		running.kill = MagicMock()
		running.wait = AsyncMock()

		finished = MagicMock()
		finished.returncode = 0

		backend._processes["w1"] = running
		backend._processes["w2"] = finished
		backend._stdout_bufs["w1"] = b"data"

		await backend.cleanup()

		running.kill.assert_called_once()
		running.wait.assert_awaited_once()
		assert backend._processes == {}
		assert backend._stdout_bufs == {}
		backend._pool.cleanup.assert_awaited_once()


# ---------------------------------------------------------------------------
# SSHBackend
# ---------------------------------------------------------------------------

class TestSSHBackend:
	@pytest.fixture()
	def hosts(self) -> list[SSHHostConfig]:
		return [
			SSHHostConfig(hostname="host-a", user="deploy", max_workers=2),
			SSHHostConfig(hostname="host-b", user="deploy", max_workers=3),
		]

	@pytest.fixture()
	def backend(self, hosts: list[SSHHostConfig]) -> SSHBackend:
		return SSHBackend(hosts=hosts)

	def test_init_empty_hosts_raises(self) -> None:
		"""SSHBackend requires at least one host."""
		with pytest.raises(ValueError, match="at least one host"):
			SSHBackend(hosts=[])

	def test_init_sets_worker_counts(self, backend: SSHBackend) -> None:
		"""Constructor initializes worker counts to zero."""
		assert backend._worker_count == {"host-a": 0, "host-b": 0}

	def test_select_host_picks_least_loaded(self, backend: SSHBackend) -> None:
		"""_select_host returns the host with fewest active workers."""
		backend._worker_count["host-a"] = 2  # at capacity
		backend._worker_count["host-b"] = 1

		chosen = backend._select_host()
		assert chosen.hostname == "host-b"

	def test_select_host_all_at_capacity(self, backend: SSHBackend) -> None:
		"""_select_host raises when all hosts are at capacity."""
		backend._worker_count["host-a"] = 2
		backend._worker_count["host-b"] = 3

		with pytest.raises(RuntimeError, match="at capacity"):
			backend._select_host()

	def test_select_host_prefers_lower_count(self, backend: SSHBackend) -> None:
		"""When both have room, picks the one with fewer workers."""
		backend._worker_count["host-a"] = 1
		backend._worker_count["host-b"] = 0

		chosen = backend._select_host()
		assert chosen.hostname == "host-b"

	def test_ssh_target_with_user(self, backend: SSHBackend) -> None:
		host = SSHHostConfig(hostname="server1", user="admin")
		assert backend._ssh_target(host) == "admin@server1"

	def test_ssh_target_without_user(self, backend: SSHBackend) -> None:
		host = SSHHostConfig(hostname="server1", user="")
		assert backend._ssh_target(host) == "server1"

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_provision_workspace(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""provision_workspace runs ssh git clone and returns packed path."""
		mock_proc = AsyncMock()
		mock_proc.returncode = 0
		mock_proc.communicate = AsyncMock(return_value=(b"Cloning...", None))
		mock_exec.return_value = mock_proc

		result = await backend.provision_workspace("w1", "git@github.com:repo.git", "main")

		# Result should contain remote_path::metadata
		assert "::" in result
		remote_path, metadata_str = result.split("::", 1)
		assert remote_path == "/tmp/mc-worker-w1"
		metadata = json.loads(metadata_str)
		assert metadata["hostname"] in ("host-a", "host-b")

		# Should have called ssh with git clone
		mock_exec.assert_awaited_once()
		call_args = mock_exec.call_args[0]
		assert call_args[0] == "ssh"
		# ssh target should be user@hostname
		assert "@" in call_args[1]

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_provision_workspace_quotes_arguments(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""provision_workspace uses shlex.quote on all interpolated values."""
		mock_proc = AsyncMock()
		mock_proc.returncode = 0
		mock_proc.communicate = AsyncMock(return_value=(b"Cloning...", None))
		mock_exec.return_value = mock_proc

		# Source repo with spaces and metacharacters
		await backend.provision_workspace("w1", "git@host:repo with spaces.git", "main; rm -rf /")

		mock_exec.assert_awaited_once()
		call_args = mock_exec.call_args[0]
		remote_cmd = call_args[2]
		import shlex
		# All three values should be quoted
		assert shlex.quote("main; rm -rf /") in remote_cmd
		assert shlex.quote("git@host:repo with spaces.git") in remote_cmd
		assert shlex.quote("/tmp/mc-worker-w1") in remote_cmd

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_release_workspace_quotes_path(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""release_workspace uses shlex.quote on the remote path."""
		mock_proc = AsyncMock()
		mock_proc.communicate = AsyncMock(return_value=(b"", None))
		mock_exec.return_value = mock_proc

		backend._worker_count["host-a"] = 1
		metadata = json.dumps({"hostname": "host-a", "user": "deploy"})
		workspace_path = f"/tmp/path with spaces::{metadata}"

		await backend.release_workspace(workspace_path)

		call_args = mock_exec.call_args[0]
		import shlex
		assert shlex.quote("/tmp/path with spaces") in call_args[2]

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_kill_quotes_worker_id_in_pkill(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""kill uses shlex.quote for worker_id in the pkill command."""
		mock_proc = MagicMock()
		mock_proc.returncode = None
		mock_proc.kill = MagicMock()
		mock_proc.wait = AsyncMock()
		backend._processes["w1; evil"] = mock_proc

		mock_cleanup = AsyncMock()
		mock_cleanup.communicate = AsyncMock(return_value=(b"", None))
		mock_exec.return_value = mock_cleanup

		metadata = json.dumps({"hostname": "host-a", "user": "deploy"})
		handle = WorkerHandle(
			worker_id="w1; evil",
			workspace_path="/tmp/mc-worker-w1",
			backend_metadata=metadata,
		)

		await backend.kill(handle)

		call_args = mock_exec.call_args[0]
		import shlex
		assert shlex.quote("mc-worker-w1; evil") in call_args[2]

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_provision_workspace_failure(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""provision_workspace raises on non-zero exit code."""
		mock_proc = AsyncMock()
		mock_proc.returncode = 1
		mock_proc.communicate = AsyncMock(return_value=(b"fatal: repo not found", None))
		mock_exec.return_value = mock_proc

		with pytest.raises(RuntimeError, match="Failed to provision"):
			await backend.provision_workspace("w1", "bad-repo", "main")

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_spawn_quotes_command(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""spawn uses shlex.quote to prevent shell injection."""
		mock_proc = AsyncMock()
		mock_proc.pid = 999
		mock_proc.returncode = None
		mock_exec.return_value = mock_proc

		workspace = '/tmp/mc-worker-w1::{"hostname":"host-a","user":"deploy"}'
		# Command contains shell metacharacters
		cmd = ["claude", "--prompt", 'fix $(rm -rf /); echo "pwned"']
		handle = await backend.spawn("w1", workspace, cmd, timeout=60)

		assert handle.worker_id == "w1"
		mock_exec.assert_awaited_once()
		call_args = mock_exec.call_args[0]
		# The remote command (third arg to ssh) should have quoted parts
		remote_cmd = call_args[2]
		# The dangerous metacharacters should be quoted/escaped
		assert "$(rm -rf /)" not in remote_cmd or "'" in remote_cmd
		# Verify shlex quoting is present
		import shlex
		assert shlex.quote('fix $(rm -rf /); echo "pwned"') in remote_cmd

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_get_output_consistent_on_repeated_calls(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""get_output returns same data on repeated calls (output is buffered)."""
		mock_proc = AsyncMock()
		mock_proc.pid = 888
		mock_proc.returncode = 0
		mock_stdout = AsyncMock()
		mock_stdout.read = AsyncMock(return_value=b"test output data")
		mock_proc.stdout = mock_stdout
		mock_exec.return_value = mock_proc

		workspace = '/tmp/mc-worker-w2::{"hostname":"host-a","user":"deploy"}'
		handle = await backend.spawn("w2", workspace, ["echo", "hello"], timeout=60)

		# First call reads from stream
		result1 = await backend.get_output(handle)
		assert result1 == "test output data"

		# Second call should return same data (not empty)
		mock_stdout.read = AsyncMock(return_value=b"")  # stream exhausted
		result2 = await backend.get_output(handle)
		assert result2 == "test output data"

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_spawn(self, mock_exec: AsyncMock, backend: SSHBackend) -> None:
		"""spawn ssh-es into the remote host and runs the command."""
		mock_proc = AsyncMock()
		mock_proc.pid = 5555
		mock_exec.return_value = mock_proc

		metadata = json.dumps({"hostname": "host-a", "user": "deploy"})
		workspace_path = f"/tmp/mc-worker-w1::{metadata}"

		handle = await backend.spawn("w1", workspace_path, ["claude", "--task", "fix"], 60)

		assert handle.worker_id == "w1"
		assert handle.pid == 5555
		assert handle.workspace_path == "/tmp/mc-worker-w1"
		assert handle.backend_metadata == metadata

		call_args = mock_exec.call_args[0]
		assert call_args[0] == "ssh"
		assert call_args[1] == "deploy@host-a"

	async def test_check_status_running(self, backend: SSHBackend) -> None:
		mock_proc = MagicMock()
		mock_proc.returncode = None
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		assert await backend.check_status(handle) == "running"

	async def test_check_status_completed(self, backend: SSHBackend) -> None:
		mock_proc = MagicMock()
		mock_proc.returncode = 0
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		assert await backend.check_status(handle) == "completed"

	async def test_check_status_failed(self, backend: SSHBackend) -> None:
		mock_proc = MagicMock()
		mock_proc.returncode = 1
		backend._processes["w1"] = mock_proc

		handle = WorkerHandle(worker_id="w1")
		assert await backend.check_status(handle) == "failed"

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_kill(self, mock_exec: AsyncMock, backend: SSHBackend) -> None:
		"""kill terminates local ssh process and sends remote pkill."""
		mock_proc = MagicMock()
		mock_proc.returncode = None
		mock_proc.kill = MagicMock()
		mock_proc.wait = AsyncMock()
		backend._processes["w1"] = mock_proc

		# Mock the remote cleanup subprocess
		mock_cleanup = AsyncMock()
		mock_cleanup.communicate = AsyncMock(return_value=(b"", None))
		mock_exec.return_value = mock_cleanup

		metadata = json.dumps({"hostname": "host-a", "user": "deploy"})
		handle = WorkerHandle(
			worker_id="w1",
			workspace_path="/tmp/mc-worker-w1",
			backend_metadata=metadata,
		)

		await backend.kill(handle)

		mock_proc.kill.assert_called_once()
		mock_proc.wait.assert_awaited_once()
		# Should also ssh pkill the remote process
		mock_exec.assert_awaited_once()
		call_args = mock_exec.call_args[0]
		assert call_args[0] == "ssh"
		assert "pkill" in call_args[2]

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_release_workspace_with_metadata(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""release_workspace ssh rm -rf the remote directory."""
		mock_proc = AsyncMock()
		mock_proc.communicate = AsyncMock(return_value=(b"", None))
		mock_exec.return_value = mock_proc

		# Bump count so we can verify it decrements
		backend._worker_count["host-a"] = 1

		metadata = json.dumps({"hostname": "host-a", "user": "deploy"})
		workspace_path = f"/tmp/mc-worker-w1::{metadata}"

		await backend.release_workspace(workspace_path)

		mock_exec.assert_awaited_once()
		call_args = mock_exec.call_args[0]
		assert call_args[0] == "ssh"
		assert "rm -rf" in call_args[2] and "/tmp/mc-worker-w1" in call_args[2]
		assert backend._worker_count["host-a"] == 0

	async def test_release_workspace_without_metadata(
		self, backend: SSHBackend,
	) -> None:
		"""release_workspace with no metadata is a no-op (no SSH call)."""
		# No :: separator, so host_info is None and nothing happens
		await backend.release_workspace("/tmp/mc-worker-w1")
		# Should not raise -- just silently skip

	async def test_cleanup(self, backend: SSHBackend) -> None:
		"""cleanup kills all running processes and resets counts."""
		running = MagicMock()
		running.returncode = None
		running.kill = MagicMock()
		running.wait = AsyncMock()

		backend._processes["w1"] = running
		backend._worker_count["host-a"] = 1

		await backend.cleanup()

		running.kill.assert_called_once()
		running.wait.assert_awaited_once()
		assert backend._processes == {}
		assert backend._worker_count == {"host-a": 0, "host-b": 0}

	@patch("mission_control.backends.ssh.asyncio.create_subprocess_exec")
	async def test_spawn_clears_stdout_collected_on_reuse(
		self, mock_exec: AsyncMock, backend: SSHBackend,
	) -> None:
		"""spawn clears _stdout_collected so reused workers get fresh output."""
		mock_proc1 = AsyncMock()
		mock_proc1.pid = 100
		mock_proc1.returncode = 0
		mock_stdout1 = AsyncMock()
		mock_stdout1.read = AsyncMock(return_value=b"output-1")
		mock_proc1.stdout = mock_stdout1

		mock_proc2 = AsyncMock()
		mock_proc2.pid = 200
		mock_proc2.returncode = 0
		mock_stdout2 = AsyncMock()
		mock_stdout2.read = AsyncMock(return_value=b"output-2")
		mock_proc2.stdout = mock_stdout2

		mock_exec.side_effect = [mock_proc1, mock_proc2]

		workspace = '/tmp/mc-worker-w1::{"hostname":"host-a","user":"deploy"}'

		# First spawn + get_output
		handle1 = await backend.spawn("w1", workspace, ["cmd1"], timeout=60)
		out1 = await backend.get_output(handle1)
		assert out1 == "output-1"
		assert "w1" in backend._stdout_collected

		# Second spawn (same worker_id) should clear _stdout_collected
		handle2 = await backend.spawn("w1", workspace, ["cmd2"], timeout=60)
		assert "w1" not in backend._stdout_collected

		out2 = await backend.get_output(handle2)
		assert out2 == "output-2"
